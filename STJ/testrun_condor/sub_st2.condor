#
# The number of parallelstage 2, jobs (= seeds) to run. Between 50-100 is
# recommended for default ncall2 100000 in powheg.input-save.
#
N                       = 100
#
# Directory where the job shell script can find things e.g. powheg
# executable(s) and input files. Default is to use the current
# directory ($ENV(PWD) in Condor).
#
InitDir                 = $ENV(PWD)
#
# Directory where the job shell script can send back it's outputs:
# integration grids, plots, event files etc ... Default is to use
# the same directory as for the job inputs, but more generally one
# can imagine wanting to send these outputs somewhere else.
#
OutDir                  = $ENV(PWD)
#
# Enter your email address here and you will receive an email when the
# first and last of the N jobs start executing on the cluster, and
# further emails when the first and last of the N jobs finish. Otherwise
# leave RHS after "=" below blank to get no emails!
#
Email                   = 
#
# Script to run powheg executable for N jobs (= seeds) for parallelstage
# 2, i.e. the Btilde function upper bound determination stage.
#
#
executable              = $(InitDir)/sub_st2.sh
arguments               = $(ProcId) $(N) $(InitDir) $(OutDir) $(Email)
#
# Where obligatory boring Condor log, error, and output files will go.
#
output                  = $(InitDir)/out/st2/st2.$(ClusterId).$(ProcId).out
error                   = $(InitDir)/err/st2/st2.$(ClusterId).$(ProcId).err
log                     = $(InitDir)/log/st2/st2.$(ClusterId).$(ProcId).log
#
# Port the environment vars in the current shell to the node where the
# jobs will execute.
#
getenv                  = True
# 
# By far most st2 jobs with ncall2 100000 will finish comfortably in 12
# hours so the following 15 hour limit allows for odd jobs on a go-slow.
#
+MaxRuntime             = 54000
#
# Bombs away again ...
#
queue $(N)

